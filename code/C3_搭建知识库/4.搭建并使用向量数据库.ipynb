{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建并使用向量数据库\n",
    "## 一、前序配置\n",
    "本节重点为搭建并使用向量数据库，因此读取数据后我们省去数据处理的环节直入主题，数据清洗等步骤可以参考第三节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../resources/data/pumpkin_book.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 如果你需要通过代理端口访问，你需要如下配置\n",
    "# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'\n",
    "# os.environ[\"HTTP_PROXY\"] = 'http://127.0.0.1:7890'\n",
    "\n",
    "# 获取folder_path下所有文件路径，储存在file_paths里\n",
    "file_paths = []\n",
    "folder_path = '../../resources/data'\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "print(file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "\n",
    "# 遍历文件路径并把实例化的loader存放在loaders里\n",
    "loaders = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "\n",
    "    file_type = file_path.split('.')[-1]\n",
    "    if file_type == 'pdf':\n",
    "        loaders.append(PyMuPDFLoader(file_path))\n",
    "    elif file_type == 'md':\n",
    "        loaders.append(UnstructuredMarkdownLoader(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载文件并存储到text\n",
    "texts = []\n",
    "\n",
    "for loader in loaders: texts.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入后的变量类型为`langchain_core.documents.base.Document`, 文档变量类型同样包含两个属性\n",
    "- `page_content` 包含该文档的内容。\n",
    "- `meta_data` 为文档相关的描述性数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一个元素的类型：<class 'langchain_core.documents.base.Document'>.\n",
      "------\n",
      "该文档的描述性数据：{'source': '../../resources/data/pumpkin_book.pdf', 'file_path': '../../resources/data/pumpkin_book.pdf', 'page': 1, 'total_pages': 196, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'xdvipdfmx (20200315)', 'creationDate': \"D:20231117152045-00'00'\", 'modDate': '', 'trapped': ''}\n",
      "------\n",
      "查看该文档的内容:\n",
      "前言\n",
      "“周志华老师的《机器学习》\n",
      "（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”\n",
      "，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。\n",
      "”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”\n",
      "。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”\n",
      "。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；\n",
      "• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；\n",
      "• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；\n",
      "• 若南瓜书里没有你想要查阅的公式，\n",
      "或者你发现南瓜书哪个地方有错误，\n",
      "请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）\n",
      "；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、\n",
      "feijuan、\n",
      "Ggmatch、\n",
      "Heitao5200、\n",
      "huaqing89、\n",
      "LongJH、\n",
      "LilRachel、\n",
      "LeoLRH、\n",
      "Nono17、\n",
      "spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”\n",
      "，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = texts[1]\n",
    "print(f\"每一个元素的类型：{type(text)}.\", \n",
    "    f\"该文档的描述性数据：{text.metadata}\", \n",
    "    f\"查看该文档的内容:\\n{text.page_content[0:]}\", \n",
    "    sep=\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解, 所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以...... 本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "• 南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；• 对于初学机器学习的小白，西瓜书第1 章和第2 章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；• 每个公式的解析和推导我们都力(zhi) 争(neng) 以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；• 若南瓜书里没有你想要查阅的公式，\n",
      "或者你发现南瓜书哪个地方有错误，\n",
      "请毫不犹豫地去我们GitHub 的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24 小时以内给您回复，超过24 小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1 版）\n",
      "最新版PDF 获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq 在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0 国际许可协议进行许可。\n",
      "\n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们了解到，周\n",
      "老师之所以省去这些推导细节的真实原因是，他本尊认为“理工科数学基础扎实点的大二下学生应该对西瓜书\n",
      "中的推导细节无困难吧，要点在书里都有了，略去的细节应能脑补或做练习”。所以......本南瓜书只能算是我\n",
      "等数学渣渣在自学的时候记下来的笔记，希望能够帮助大家都成为一名合格的“理工科数学基础扎实点的大二\n",
      "下学生”。\n",
      "使用说明\n",
      "南瓜书的所有内容都是以西瓜书的内容为前置知识进行表述的，所以南瓜书的最佳使用方法是以西瓜书\n",
      "为主线，遇到自己推导不出来或者看不懂的公式时再来查阅南瓜书；对于初学机器学习的小白，西瓜书第1章和第2章的公式强烈不建议深究，简单过一下即可，等你学得\n",
      "有点飘的时候再回来啃都来得及；每个公式的解析和推导我们都力(zhi)争(neng)以本科数学基础的视角进行讲解，所以超纲的数学知识\n",
      "我们通常都会以附录和参考文献的形式给出，感兴趣的同学可以继续沿着我们给的资料进行深入学习；若南瓜书里没有你想要查阅的公式，\n",
      "或者你发现南瓜书哪个地方有错误，\n",
      "请毫不犹豫地去我们GitHub的\n",
      "Issues（地址：https://github.com/datawhalechina/pumpkin-book/issues）进行反馈，在对应版块\n",
      "提交你希望补充的公式编号或者勘误信息，我们通常会在24小时以内给您回复，超过24小时未回复的\n",
      "话可以微信联系我们（微信号：at-Sm1les）；\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "在线阅读地址：https://datawhalechina.github.io/pumpkin-book（仅供第1版）\n",
      "最新版PDF获取地址：https://github.com/datawhalechina/pumpkin-book/releases\n",
      "编委会\n",
      "主编：Sm1les、archwalker、jbb0523\n",
      "编委：juxiao、Majingmin、MrBigFan、shanry、Ye980226\n",
      "封面设计：构思-Sm1les、创作-林王茂盛\n",
      "致谢\n",
      "特别感谢awyd234、feijuan、Ggmatch、Heitao5200、huaqing89、LongJH、LilRachel、LeoLRH、Nono17、spareribs、sunchaothu、StevenLzq在最早期的时候对南瓜书所做的贡献。\n",
      "扫描下方二维码，然后回复关键词“南瓜书”，即可加入“南瓜书读者交流群”\n",
      "版权声明\n",
      "本作品采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'[^\\u4e00-\\u9fff](\\n)[^\\u4e00-\\u9fff]', re.DOTALL)\n",
    "texts[1].page_content = re.sub(pattern, lambda match: match.group(0).replace('\\n', ''), texts[1].page_content)\n",
    "print(texts[1].page_content)\n",
    "\n",
    "texts[1].page_content = texts[1].page_content.replace('•', '')\n",
    "texts[1].page_content = texts[1].page_content.replace(' ', '')\n",
    "print(texts[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 切分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "split_docs = text_splitter.split_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、构建Chroma向量库\n",
    "\n",
    "Langchain 集成了超过 30 个不同的向量存储库。我们选择 Chroma 是因为它轻量级且数据存储在内存中，这使得它非常容易启动和开始使用。\n",
    "\n",
    "LangChain 可以直接使用 OpenAI 和百度千帆的 Embedding，同时，我们也可以针对其不支持的 Embedding API 进行自定义，例如，我们可以基于 LangChain 提供的接口，封装一个 zhupuai_embedding，来将智谱的 Embedding API 接入到 LangChain 中。在本章的[附LangChain自定义Embedding封装讲解](./附LangChain自定义Embedding封装讲解.ipynb)中，我们以智谱 Embedding API 为例，介绍了如何将其他 Embedding API 封装到 LangChain\n",
    "中，欢迎感兴趣的读者阅读。\n",
    "\n",
    "**注：如果你使用智谱 API，你可以参考讲解内容实现封装代码，也可以直接使用我们已经封装好的代码[zhipuai_embedding.py](./zhipuai_embedding.py)，将该代码同样下载到本 Notebook 的同级目录，就可以直接导入我们封装的函数。在下面的代码 Cell 中，我们默认使用了智谱的 Embedding，将其他两种 Embedding 使用代码以注释的方法呈现，如果你使用的是百度 API 或者 OpenAI API，可以根据情况来使用下方 Cell 中的代码。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# 使用 OpenAI Embedding\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "# 使用百度千帆 Embedding\n",
    "# from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint\n",
    "# 使用我们自己封装的智谱 Embedding，需要将封装代码下载到本地使用\n",
    "# from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "# 定义 Embeddings\n",
    "embedding = OpenAIEmbeddings() \n",
    "# embedding = ZhipuAIEmbeddings()\n",
    "# embedding = QianfanEmbeddingsEndpoint()\n",
    "\n",
    "# 定义持久化路径\n",
    "persist_directory = '../../resources/data/vector_db/chroma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '../../data_base/vector_db/chroma'  # 删除旧的数据库文件（如果文件夹中有文件的话），windows电脑请手动删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs[:20], # 为了速度，只选择前 20 个切分的 doc 进行生成；使用千帆时因QPS限制，建议选择前 5 个doc\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory  # 允许我们将persist_directory目录保存到磁盘上\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之后，我们要确保通过运行 vectordb.persist 来持久化向量数据库，以便我们在未来的课程中使用。\n",
    "\n",
    "让我们保存它，以便以后使用！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：20\n"
     ]
    }
   ],
   "source": [
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、向量检索\n",
    "### 3.1 相似度检索\n",
    "Chroma的相似度搜索使用的是余弦距离，即：\n",
    "$$\n",
    "similarity = cos(A, B) = \\frac{A \\cdot B}{\\parallel A \\parallel \\parallel B \\parallel} = \\frac{\\sum_1^n a_i b_i}{\\sqrt{\\sum_1^n a_i^2}\\sqrt{\\sum_1^n b_i^2}}\n",
    "$$\n",
    "其中$a_i$、$b_i$分别是向量$A$、$B$的分量。\n",
    "\n",
    "当你需要数据库返回严谨的按余弦相似度排序的结果时可以使用`similarity_search`函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"什么是机器学习\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的内容数：3\n"
     ]
    }
   ],
   "source": [
    "sim_docs = vectordb.similarity_search(question,k=3)\n",
    "print(f\"检索到的内容数：{len(sim_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检索到的第0个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2 版》\n",
      "←_←\n",
      "目录\n",
      "第1 章绪论\n",
      "1\n",
      "1.1\n",
      "引言. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1\n",
      "1.2\n",
      "基本术语\n",
      ". . . . . . . . . . . . . . . . . .\n",
      "--------------\n",
      "检索到的第1个内容: \n",
      "前言\n",
      "“周志华老师的《机器学习》（西瓜书）是机器学习领域的经典入门教材之一，周老师为了使尽可能多的读\n",
      "者通过西瓜书对机器学习有所了解,所以在书中对部分公式的推导细节没有详述，但是这对那些想深究公式推\n",
      "导细节的读者来说可能“不太友好”，本书旨在对西瓜书里比较难理解的公式加以解析，以及对部分公式补充\n",
      "具体的推导细节。”\n",
      "读到这里，大家可能会疑问为啥前面这段话加了引号，因为这只是我们最初的遐想，后来我们\n",
      "--------------\n",
      "检索到的第2个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2 版》\n",
      "←_←\n",
      "3.3.1\n",
      "式(3.27) 的推导\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "23\n",
      "3.3.2\n",
      "梯度下降法. . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(sim_docs):\n",
    "    print(f\"检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MMR检索\n",
    "如果只考虑检索出内容的相关性会导致内容过于单一，可能丢失重要信息。\n",
    "\n",
    "最大边际相关性 (`MMR, Maximum marginal relevance`) 可以帮助我们在保持相关性的同时，增加内容的丰富度。\n",
    "\n",
    "核心思想是在已经选择了一个相关性高的文档之后，再选择一个与已选文档相关性较低但是信息丰富的文档。这样可以在保持相关性的同时，增加内容的多样性，避免过于单一的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmr_docs = vectordb.max_marginal_relevance_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMR 检索到的第0个内容: \n",
      "→_→\n",
      "欢迎去各大电商平台选购纸质版南瓜书《机器学习公式详解第2 版》\n",
      "←_←\n",
      "目录\n",
      "第1 章绪论\n",
      "1\n",
      "1.1\n",
      "引言. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1\n",
      "1.2\n",
      "基本术语\n",
      ". . . . . . . . . . . . . . . . . .\n",
      "--------------\n",
      "MMR 检索到的第1个内容: \n",
      "3\n",
      "1.4.1\n",
      "式(1.1) 和式(1.2) 的解释. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "4\n",
      "第2 章模型评估与选择\n",
      "5\n",
      "2.1\n",
      "经验误差与过拟合\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "5\n",
      "--------------\n",
      "MMR 检索到的第2个内容: \n",
      "23\n",
      "→_→\n",
      "配套视频教程：https://www.bilibili.com/video/BV1Mh411e7VU\n",
      "←_←\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, sim_doc in enumerate(mmr_docs):\n",
    "    print(f\"MMR 检索到的第{i}个内容: \\n{sim_doc.page_content[:200]}\", end=\"\\n--------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_universe_2.x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
